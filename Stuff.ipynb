{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gff2bed\n",
    "import Orthoscripts\n",
    "\n",
    "# Disable chained assignments\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asterias rubens\n",
    "Astrub = Orthoscripts.readBED(\"Data/Genelists/Asterias.rubens.genelist.bed\")\n",
    "\n",
    "# Holothuria leucospilota\n",
    "Holleu = Orthoscripts.readBED(\"Data/Genelists/Holothuria.leucospilota.genelist.bed\")\n",
    "\n",
    "# Paracentrotus livides\n",
    "Parliv = Orthoscripts.readBED(\"Data/Genelists/Paracentrotus.lividus.genelist.bed\")\n",
    "\n",
    "# Branchiostoma lanceolatum\n",
    "Bralan = Orthoscripts.readBED(\"Data/Genelists/Branchiostoma.lanceolatum.genelist.bed\")\n",
    "\n",
    "# Branchiostoma floridae\n",
    "Braflo = Orthoscripts.readBED(\"Data/Genelists/Branchiostoma.floridae.genelist.bed\")\n",
    "\n",
    "# Marthasterias glacialis\n",
    "Margla = Orthoscripts.readBED(\"Data/Genelists/Marthasterias.glacialis.genelist.bed\")\n",
    "\n",
    "# Pecten maximus\n",
    "Pecmax = Orthoscripts.readBED(\"Data/Genelists/Pecmax.genelist.bed\")\n",
    "\n",
    "# Stichopus chloronotus\n",
    "Stichl = Orthoscripts.readBED(\"Data/Genelists/Stichopus.chloronotus.genelist.bed\")\n",
    "\n",
    "# Amphiura filiformis \n",
    "Ampfil = Orthoscripts.readBED(\"Data/Genelists/Amphiura.filiformis.genelist.bed\")\n",
    "\n",
    "# Ephydatia muelleri\n",
    "Ephmue = Orthoscripts.readBED(\"Data/Genelists/Ephydatia.muelleri.genelist.bed\")\n",
    "\n",
    "# Ancestor \n",
    "Ancestor = Orthoscripts.readBED(\"Data/Genelists/Ancestor.genelist.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import orthologs\n",
    "Astrub_Holleu = np.loadtxt(\"Data/Orthologs/Asterias.rubens+Holothuria.leucospilota.txt\", dtype = \"str\")\n",
    "\n",
    "Astrub_Parliv = np.loadtxt(\"Data/Orthologs/Asterias.rubens+Paracentrotus.lividus.txt\", dtype = \"str\")\n",
    "\n",
    "Holleu_Parliv = np.loadtxt(\"Data/Orthologs/Holothuria.leucospilota+Paracentrotus.lividus.txt\", dtype = \"str\")\n",
    "\n",
    "Margla_Bralan = np.loadtxt(\"Data/Orthologs/Marthasterias.glacialis+Branchiostoma.lanceolatum.txt\", dtype = \"str\")\n",
    "\n",
    "Margla_Pecmax = np.loadtxt(\"Data/Orthologs/Marthasterias.glacialis+Pecten.maximus.txt\", dtype = \"str\")\n",
    "\n",
    "Margla_Stichl = np.loadtxt(\"Data/Orthologs/Marthasterias.glacialis+Stichopus.chloronotus.txt\", dtype = \"str\")\n",
    "\n",
    "Pecmax_Bralan = np.loadtxt(\"Data/Orthologs/Pecten.maximus+Branchiostoma.lanceolatum.txt\", dtype = \"str\")\n",
    "\n",
    "Stichl_Bralan = np.loadtxt(\"Data/Orthologs/Stichopus.chloronotus+Branchiostoma.lanceolatum.txt\", dtype = \"str\")\n",
    "\n",
    "Stichl_Pecmax = np.loadtxt(\"Data/Orthologs/Stichopus.chloronotus+Pecten.maximus.txt\", dtype = \"str\")\n",
    "\n",
    "Pecmax_Holleu = np.loadtxt(\"Orthology pipeline/orthologs/Pecmax+Holleu_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Holleu_Bralan = np.loadtxt(\"Orthology pipeline/orthologs/Holleu+Bralan_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Pecmax_Bralan = np.loadtxt(\"Orthology pipeline/orthologs/Pecmax+Bralan_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Pecmax_Braflo = np.loadtxt(\"Orthology pipeline/orthologs/Pecmax+Braflo_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Holleu_Braflo = np.loadtxt(\"Orthology pipeline/orthologs/Holleu+Braflo_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Holleu_Ampfil = np.loadtxt(\"Data/Orthologs/Holothuria.leucospilota+Amphiura.filiformis.txt\", dtype = \"str\")\n",
    "\n",
    "Braflo_Ephmue = np.loadtxt(\"Orthology pipeline/orthologs/Braflo+Ephmue_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Holleu_Ephmue = np.loadtxt(\"Orthology pipeline/orthologs/Holleu+Ephmue_sensitive.txt\", dtype = \"str\")\n",
    "\n",
    "Pecmax_Ephmue = np.loadtxt(\"Orthology pipeline/orthologs/Pecmax+Ephmue_sensitive.txt\", dtype = \"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Astrub = Astrub.loc[Astrub['Chromosome'].str.contains('chr')]\n",
    "Bralan = Bralan.loc[Bralan['Chromosome'].str.contains('BFL_')]\n",
    "Braflo = Braflo.loc[Braflo['Chromosome'].str.contains('BFL_')]\n",
    "Pecmax = Pecmax.loc[Pecmax['Chromosome'].str.contains('PYE_')]\n",
    "\n",
    "# Ephmue genelist: remove suffix\n",
    "Ephmue['Name'] = Ephmue['Name'].str.rsplit('.t1').str.get(0)\n",
    "\n",
    "# Parliv genelist: select chromosomal scaffolds\n",
    "Parliv = Orthoscripts.unscaff(Parliv, 100)\n",
    "Ampfil = Orthoscripts.unscaff(Ampfil, 100)\n",
    "Ephmue = Orthoscripts.unscaff(Ephmue, 600)\n",
    "\n",
    "Astrub_Parliv = Orthoscripts.orthFix(Astrub_Parliv, 'B', 'Parliv_', 1)\n",
    "Margla_Bralan = Orthoscripts.orthFix(Margla_Bralan, 'A', '.1', 0)\n",
    "Margla_Stichl = Orthoscripts.orthFix(Margla_Stichl, 'A', '.1', 0)\n",
    "Margla_Stichl = Orthoscripts.orthFix(Margla_Stichl, 'B', '.1', 0)\n",
    "Margla_Pecmax = Orthoscripts.orthFix(Margla_Pecmax, 'B', '.1', 0)\n",
    "Holleu_Ampfil = Orthoscripts.orthFix(Holleu_Ampfil, 'B', '.1', 0)\n",
    "Holleu_Bralan = Orthoscripts.orthFix(Holleu_Bralan, 'B', '_', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old orthology function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthofy(genelistA, genelistB, orthologies):\n",
    "    \n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    genelistA: gene list for species A\n",
    "    genelistB: gene list for species B\n",
    "    orthologies: orthology dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make ortholog dictionaries\n",
    "    A_orthdict = dict(zip(orthologies[:, 1], orthologies[:, 0]))\n",
    "    B_orthdict = dict(zip(orthologies[:, 2], orthologies[:, 0]))\n",
    "\n",
    "    # Replace genelist values with ortholog dictionaries\n",
    "    A_data = genelistA.replace({'Name': A_orthdict})\n",
    "    B_data = genelistB.replace({'Name' : B_orthdict})\n",
    "    \n",
    "    # Add column for orthologs: 1 if ortholog, 0 if not\n",
    "    B_data['Ortholog'] = B_data['Name'].apply(lambda x:1 if 'ortholog' in x.lower() else 0)\n",
    "    A_data['Ortholog'] = A_data['Name'].apply(lambda x:1 if 'ortholog' in x.lower() else 0)\n",
    "    \n",
    "    # Isolate orthologies\n",
    "    A_ortho = A_data.loc[A_data['Ortholog'] == 1]\n",
    "    A_dict = dict(zip(A_ortho.Name, A_ortho.Chromosome))\n",
    "\n",
    "    B_ortho = B_data.loc[B_data['Ortholog'] == 1]\n",
    "    B_dict = dict(zip(B_ortho.Name, B_ortho.Chromosome))\n",
    "    \n",
    "    # Seperate all orthology entries into new dataframe\n",
    "    AB_data = pd.DataFrame({'Orthologs' : orthologies[:, 0],\n",
    "                            'speciesA' : orthologies[:, 0],\n",
    "                            'speciesB' : orthologies[:, 0]})\n",
    "    \n",
    "    # Replace location in A and B with orthology dictionary keys\n",
    "    AB_data['speciesA'] = AB_data['speciesB'].map(A_dict)\n",
    "    AB_data['speciesB'] = AB_data['speciesB'].map(B_dict)\n",
    "    \n",
    "    # Calculate number of orthologs for each pair of chromosomes\n",
    "    AB_data = AB_data.groupby(['speciesA', 'speciesB']).count().reset_index()\n",
    "    \n",
    "    A = A_data.Name.values.tolist()\n",
    "    B = B_data.Name.values.tolist()\n",
    "    M = len(list(set(A) & set(B)))\n",
    "    \n",
    "    # Define inner function for hypergeometric testing\n",
    "    def hypertest(chrA, chrB):\n",
    "        nA = AB_data.loc[(AB_data['speciesA'] == chrA), 'Orthologs'].sum()\n",
    "        nB = AB_data.loc[(AB_data['speciesB'] == chrB), 'Orthologs'].sum()\n",
    "        x = AB_data.loc[(AB_data['speciesA'] == chrA) & (AB_data['speciesB'] == chrB), 'Orthologs'].sum()\n",
    "    \n",
    "        p = stats.hypergeom.sf(x - 1, M, nA, nB)\n",
    "        \n",
    "        return p\n",
    "\n",
    "    # Conduct hypergeometric testing\n",
    "    AB_data['p-Values'] = AB_data.apply(lambda x : hypertest(x['speciesA'], x['speciesB']), axis = 1)\n",
    "    \n",
    "    # Apply BH testing correction\n",
    "    AB_data['Results'], AB_data['p-Values'] = pg.multicomp(AB_data['p-Values'], method = 'fdr_bh')\n",
    "    \n",
    "    # Remove all rows that have been rejected in BH correction\n",
    "    AB_data = AB_data.loc[AB_data['Results'] == True]\n",
    "    \n",
    "    return AB_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print whole output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints whole output\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "    print(Astrub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace df values with dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Astrub['PGenes'] = Astrub['PGenes'].map(lambda x: orthdictA.get(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Pecmax scaffolds to chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pecmax data: Replace scaffold names with chromosome names\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_2', 'PYE_1')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_18', 'PYE_2')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_19', 'PYE_3')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_16', 'PYE_4')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_4', 'PYE_5')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_7', 'PYE_6')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_11', 'PYE_7')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_15', 'PYE_8')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_17', 'PYE_9')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_10', 'PYE_10')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_1', 'PYE_11')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_3', 'PYE_12')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_12', 'PYE_13')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_5', 'PYE_14')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_9', 'PYE_15')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_14', 'PYE_16')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_13', 'PYE_17')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_8', 'PYE_18')\n",
    "Pecmax = Pecmax.replace('HiC_scaffold_6', 'PYE_19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Ephmue scaffolds to chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ephmue['Name'] = Ephmue['Name'].str.rsplit('.t1').str.get(0)\n",
    "Ephmue = Ephmue.replace('scaffold_0001', 'EMU_1')\n",
    "Ephmue = Ephmue.replace('scaffold_0002', 'EMU_2')\n",
    "Ephmue = Ephmue.replace('scaffold_0003', 'EMU_3')\n",
    "Ephmue = Ephmue.replace('scaffold_0004', 'EMU_4')\n",
    "Ephmue = Ephmue.replace('scaffold_0005', 'EMU_5')\n",
    "Ephmue = Ephmue.replace('scaffold_0006', 'EMU_6')\n",
    "Ephmue = Ephmue.replace('scaffold_0007', 'EMU_7')\n",
    "Ephmue = Ephmue.replace('scaffold_0008', 'EMU_8')\n",
    "Ephmue = Ephmue.replace('scaffold_0009', 'EMU_9')\n",
    "Ephmue = Ephmue.replace('scaffold_0010', 'EMU_10')\n",
    "Ephmue = Ephmue.replace('scaffold_0011', 'EMU_11')\n",
    "Ephmue = Ephmue.replace('scaffold_0012', 'EMU_12')\n",
    "Ephmue = Ephmue.replace('scaffold_0013', 'EMU_13')\n",
    "Ephmue = Ephmue.replace('scaffold_0014', 'EMU_14')\n",
    "Ephmue = Ephmue.replace('scaffold_0015', 'EMU_15')\n",
    "Ephmue = Ephmue.replace('scaffold_0016', 'EMU_16')\n",
    "Ephmue = Ephmue.replace('scaffold_0017', 'EMU_17')\n",
    "Ephmue = Ephmue.replace('scaffold_0018', 'EMU_18')\n",
    "Ephmue = Ephmue.replace('scaffold_0019', 'EMU_19')\n",
    "Ephmue = Ephmue.replace('scaffold_0020', 'EMU_20')\n",
    "Ephmue = Ephmue.replace('scaffold_0021', 'EMU_21')\n",
    "Ephmue = Ephmue.replace('scaffold_0022', 'EMU_22')\n",
    "Ephmue = Ephmue.replace('scaffold_00023', 'EMU_23')\n",
    "np.savetxt(r'Data/Genelists/Ephmue.genelist.bed', Ephmue.values, fmt = '%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old ancestral chromosome code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB = orthofy(Pecmax, Braflo, Pecmax_Braflo)\n",
    "PB = PB.dropna()\n",
    "\n",
    "# Make matrix with corresponding chromosomes\n",
    "Amp = ['BFL_11', 'BFL_10', 'BFL_16', 'BFL_8', 'BFL_3', 'BFL_1', 'BFL_18', 'BFL_14', 'BFL_15', 'BFL_5', 'BFL_7', 'BFL_3', 'BFL_17', 'BFL_3', 'BFL_19', 'BFL_12', 'BFL_1', 'BFL_13', 'BFL_2', 'BFL_2', 'BFL_6', 'BFL_9', 'BFL_4', 'BFL_4']\n",
    "Sca = ['PYE_10', 'PYE_13', 'PYE_1', 'PYE_1', 'PYE_17', 'PYE_5', 'PYE_19', 'PYE_15', 'PYE_4', 'PYE_6', 'PYE_7', 'PYE_2', 'PYE_18', 'PYE_2', 'PYE_3', 'PYE_14', 'PYE_16', 'PYE_2', 'PYE_4', 'PYE_9', 'PYE_8', 'PYE_3', 'PYE_11', 'PYE_12']\n",
    "Anc = ['G', 'B1', 'B2', 'M', 'C2', 'A1aA1b', 'B3', 'P', 'L', 'EaEb', 'F', 'QbQa', 'J1', 'QcQd', 'O2', 'N', 'A2', 'H', 'J2', 'C1', 'D', 'K', 'I', 'O1']\n",
    "ChrCorr = np.column_stack((Sca, Amp, Anc))\n",
    "\n",
    "# Make dataframe with corresponding chromosomes\n",
    "PBgenes = pd.DataFrame()\n",
    "for i in range (0, 24): \n",
    "    PBorthologs = PB.loc[(PB['A'] == ChrCorr[i, 0]) & (PB['B'] == ChrCorr[i, 1])]\n",
    "    PBorthologs['Chr'] = ChrCorr[i, 2]\n",
    "\n",
    "    PBgenes = pd.concat([PBgenes, PBorthologs])\n",
    "\n",
    "# Manually add PYE_12\n",
    "PBorthologs = PB.loc[(PB['A'] == 'PYE_12') & (PB['B'] != 'BFL_4')]\n",
    "PBorthologs['Chr'] = 'R'\n",
    "PBgenes = pd.concat([PBgenes, PBorthologs])\n",
    "\n",
    "PBgenes['BGenes'] = PBgenes.loc[:, 'Orthologs']\n",
    "PBgenes = PBgenes.rename(columns = {'Orthologs' : 'PGenes'})\n",
    "PBgenes = PBgenes[['Chr', 'A', 'PGenes', 'B', 'BGenes']]\n",
    "\n",
    "# Make reverse ortholog dictionaries (ortholog : gene name)\n",
    "orthdictA = dict(zip(Pecmax_Braflo[:, 0], Pecmax_Braflo[:, 1]))\n",
    "orthdictB = dict(zip(Pecmax_Braflo[:, 0], Pecmax_Braflo[:, 2]))\n",
    "\n",
    "# Replace values\n",
    "PBgenes['PGenes'] = PBgenes['PGenes'].map(lambda x: orthdictA.get(x, x))\n",
    "PBgenes['BGenes'] = PBgenes['BGenes'].map(lambda x: orthdictB.get(x, x))\n",
    "\n",
    "# Make dictionaries (H gene name : P/B gene name)\n",
    "orthdictP = dict(zip(Pecmax_Holleu[:, 1], Pecmax_Holleu[:, 2]))\n",
    "orthdictB = dict(zip(Holleu_Braflo[:, 2], Holleu_Braflo[:, 1]))\n",
    "\n",
    "# Replace values\n",
    "PBgenes['PGenes'] = PBgenes['PGenes'].map(lambda x: orthdictP.get(x, x))\n",
    "PBgenes['BGenes'] = PBgenes['BGenes'].map(lambda x: orthdictB.get(x, x))\n",
    "\n",
    "# Select all values orthologous in both columns\n",
    "Ancestor = PBgenes.loc[(PBgenes['PGenes'].str.contains('gene-HOLleu_')) & \n",
    "                       (PBgenes['BGenes'].str.contains('gene-HOLleu_'))]\n",
    "\n",
    "Ancestor = Ancestor.rename(columns = {'Chr' : 'Chromosome',\n",
    "                                      'PGenes' : 'Name', \n",
    "                                      'A' : 'Pchr',\n",
    "                                      'B' : 'Bchr'})\n",
    "\n",
    "PB = orthofy(Pecmax, Braflo, Pecmax_Braflo)\n",
    "PB = PB.dropna()\n",
    "\n",
    "# Make matrix with corresponding chromosomes\n",
    "Amp = ['BFL_11', 'BFL_10', 'BFL_16', 'BFL_8', 'BFL_3', 'BFL_1', 'BFL_18', 'BFL_14', 'BFL_15', 'BFL_5', 'BFL_7', 'BFL_3', 'BFL_17', 'BFL_3', 'BFL_19', 'BFL_12', 'BFL_1', 'BFL_13', 'BFL_2', 'BFL_2', 'BFL_6', 'BFL_9', 'BFL_4', 'BFL_4']\n",
    "Sca = ['PYE_10', 'PYE_13', 'PYE_1', 'PYE_1', 'PYE_17', 'PYE_5', 'PYE_19', 'PYE_15', 'PYE_4', 'PYE_6', 'PYE_7', 'PYE_2', 'PYE_18', 'PYE_2', 'PYE_3', 'PYE_14', 'PYE_16', 'PYE_2', 'PYE_4', 'PYE_9', 'PYE_8', 'PYE_3', 'PYE_11', 'PYE_12']\n",
    "Anc = ['G', 'B1', 'B2', 'M', 'C2', 'A1aA1b', 'B3', 'P', 'L', 'EaEb', 'F', 'QbQa', 'J1', 'QcQd', 'O2', 'N', 'A2', 'H', 'J2', 'C1', 'D', 'K', 'I', 'O1']\n",
    "ChrCorr = np.column_stack((Sca, Amp, Anc))\n",
    "\n",
    "# Make dataframe with corresponding chromosomes\n",
    "PBgenes = pd.DataFrame()\n",
    "for i in range (0, 24): \n",
    "    PBorthologs = PB.loc[(PB['A'] == ChrCorr[i, 0]) & (PB['B'] == ChrCorr[i, 1])]\n",
    "    PBorthologs['Chr'] = ChrCorr[i, 2]\n",
    "\n",
    "    PBgenes = pd.concat([PBgenes, PBorthologs])\n",
    "\n",
    "# Manually add PYE_12\n",
    "PBorthologs = PB.loc[(PB['A'] == 'PYE_12') & (PB['B'] != 'BFL_4')]\n",
    "PBorthologs['Chr'] = 'R'\n",
    "PBgenes = pd.concat([PBgenes, PBorthologs])\n",
    "\n",
    "PBgenes['BGenes'] = PBgenes.loc[:, 'Orthologs']\n",
    "PBgenes = PBgenes.rename(columns = {'Orthologs' : 'PGenes'})\n",
    "PBgenes = PBgenes[['Chr', 'A', 'PGenes', 'B'BGenes']]\n",
    "\n",
    "# Make reverse ortholog dictionaries (ortholog : gene name)\n",
    "orthdictA = dict(zip(Pecmax_Braflo[:, 0], Pecmax_Braflo[:, 1]))\n",
    "orthdictB = dict(zip(Pecmax_Braflo[:, 0], Pecmax_Braflo[:, 2]))\n",
    "\n",
    "# Replace values\n",
    "PBgenes['PGenes'] = PBgenes['PGenes'].map(lambda x: orthdictA.get(x, x))\n",
    "PBgenes['BGenes'] = PBgenes['BGenes'].map(lambda x: orthdictB.get(x, x))\n",
    "\n",
    "# Make dictionaries (H gene name : P/B gene name)\n",
    "orthdictP = dict(zip(Pecmax_Holleu[:, 1], Pecmax_Holleu[:, 2]))\n",
    "orthdictB = dict(zip(Holleu_Braflo[:, 2], Holleu_Braflo[:, 1]))\n",
    "\n",
    "# Replace values\n",
    "PBgenes['PGenes'] = PBgenes['PGenes'].map(lambda x: orthdictP.get(x, x))\n",
    "PBgenes['BGenes'] = PBgenes['BGenes'].map(lambda x: orthdictB.get(x, x))\n",
    "\n",
    "# Select all values orthologous in both columns\n",
    "Ancestor = PBgenes.loc[(PBgenes['PGenes'].str.contains('gene-HOLleu_')) & \n",
    "                       (PBgenes['BGenes'].str.contains('gene-HOLleu_'))]\n",
    "\n",
    "Ancestor = Ancestor[['Chr', 'PGenes']]\n",
    "Ancestor = Ancestor.rename(columns = {'Chr' : 'Chromosome',\n",
    "                                      'PGenes' : 'Name'})\n",
    "\n",
    "# Select all values orthologous only in one column\n",
    "AncP = PBgenes.loc[(PBgenes['PGenes'].str.contains('gene-HOLleu_')) & (PBgenes['BGenes'].str.contains('gene-HOLleu_') == False)]\n",
    "AncB = PBgenes.loc[(PBgenes['BGenes'].str.contains('gene-HOLleu_')) & (PBgenes['PGenes'].str.contains('gene-HOLleu_') == False)]\n",
    "\n",
    "AncP = AncP[['Chr', 'PGenes']]\n",
    "AncB = AncB[['Chr', 'BGenes']]\n",
    "\n",
    "Ancestor = pd.concat([Ancestor, \n",
    "                      AncP.rename(columns = {'Chr' : 'Chromosome', 'PGenes' : 'Name'}), \n",
    "                      AncB.rename(columns = {'Chr' : 'Chromosome', 'BGenes' : 'Name'})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make ortholog dictionaries\n",
    "Aorthdict = dict(zip(ortholog[ :,1], ortholog[ :,0]))\n",
    "Horthdict = dict(zip(ortholog[ :,2], ortholog[ :,0]))\n",
    "\n",
    "# Replace values with ortholog dictionary\n",
    "Adata = Adata.replace({\"Name\": Aorthdict})\n",
    "\n",
    "# Edit Hdata values (Hchr1 -> chr1)\n",
    "val2 = ['Hchr1', 'Hchr2', 'Hchr3', 'Hchr4', 'Hchr5', 'Hchr6', \n",
    "        'Hchr7', 'Hchr8', 'Hchr9', 'Hchr10', 'Hchr11', 'Hchr12',\n",
    "        'Hchr13', 'Hchr14', 'Hchr15', 'Hchr16', 'Hchr17', \n",
    "        'Hchr18', 'Hchr19', 'Hchr20', 'Hchr21', 'Hchr22', 'Hchr23']\n",
    "\n",
    "for i in range(0, 23):\n",
    "    Hdata = Hdata.replace(val2[i], val1[i])\n",
    "\n",
    "# Replace values with ortholog dictionary\n",
    "Hdata = Hdata.replace({\"Name\" : Horthdict})\n",
    "\n",
    "# Add ortholog column, value is 1 or 0\n",
    "Hdata[\"Ortholog\"] = Hdata[\"Name\"].apply(lambda x:1 if 'ortholog' in x.lower() else 0)\n",
    "Adata[\"Ortholog\"] = Adata[\"Name\"].apply(lambda x:1 if 'ortholog' in x.lower() else 0)\n",
    "\n",
    "# Make new dataframe with just the orthologs\n",
    "Hortho = Hdata.loc[Hdata['Ortholog'] == 1]\n",
    "Hdict = dict(zip(Hortho.Name, Hortho.Chromosome))\n",
    "\n",
    "Aortho = Adata.loc[Adata['Ortholog'] == 1]\n",
    "Adict = dict(zip(Aortho.Name, Aortho.Chromosome))\n",
    "\n",
    "# Calculate number of orthologs for each chromosome\n",
    "HChr = []\n",
    "for i in val1:\n",
    "    HChr.append(len(Hortho.loc[(Hortho['Chromosome'] == i)]))\n",
    "print(HChr)\n",
    "\n",
    "AChr = []\n",
    "for i in val1:\n",
    "    AChr.append(len(Aortho.loc[(Aortho['Chromosome'] == i)]))\n",
    "print(AChr)\n",
    "\n",
    "# Make new dataframe\n",
    "Odata = pd.DataFrame()\n",
    "Odata['Orthologs'] = ortholog[:, 0]\n",
    "Odata['A'] = ortholog[:, 0]\n",
    "Odata['H'] = ortholog[:, 0]\n",
    "\n",
    "# Replace location in A and H with orthology dictionary keys\n",
    "Odata['A'] = Odata['A'].map(Adict)\n",
    "Odata['H'] = Odata['H'].map(Hdict)\n",
    "\n",
    "# Calculate number of orthologs for each pair of chromosomes\n",
    "Odata = Odata.groupby(['A', 'H']).count()\n",
    "Odata = Odata.reset_index()\n",
    "\n",
    "# Plot\n",
    "sns.scatterplot(data = Odata, x = 'A', y = 'H', size = 'Orthologs', hue = 'Orthologs', palette = \"crest\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=10)\n",
    "plt.xlabel(\"Asterias rubens\")\n",
    "plt.ylabel(\"Holothuria leucospilota\")\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Removing values <100:\n",
    "minOdata = Odata.loc[Odata[\"Orthologs\"] >= 100]\n",
    "\n",
    "# Plot\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "sns.scatterplot(data = minOdata, x = 'A', y = 'H', size = 'Orthologs', hue = 'Orthologs', palette = \"crest\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', fontsize=10)\n",
    "plt.xlabel(\"Asterias rubens\")\n",
    "plt.ylabel(\"Holothuria leucospilota\")\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Hypergeometric test\n",
    "def hypertest(chrA, chrB, dataset = Odata, speciesA = 'A', speciesB = 'B'):\n",
    "    \"\"\"\n",
    "    M: total number of orthologs on both AchrN and BchrN\n",
    "    nA, nB: number of orthologs on AchrN and BchrN individually\n",
    "    x: number of orthologs on both AchrN and BchrN\n",
    "    \"\"\"\n",
    "    nA = dataset.loc[(dataset['A'] == chrA), 'Orthologs'].sum()\n",
    "    nB = dataset.loc[(dataset['H'] == chrB), 'Orthologs'].sum()\n",
    "    x = dataset.loc[(dataset['A'] == chrA) & (dataset['H'] == chrB), 'Orthologs'].sum()\n",
    "    \n",
    "    p = stats.hypergeom.sf(x, (nA + nB), nA, nB)\n",
    "     \n",
    "    print(nA, nB, (nA + nB), x, p)\n",
    "    \n",
    "hypertest('chr1', 'chr3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if r <= 0.30:\n",
    "        if len(ancestor) < 2: continue\n",
    "        speciesA, log = fission(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "    \n",
    "    elif r <= 0.45:\n",
    "        speciesA, log = translocation(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "    \n",
    "    elif r <= 0.70:\n",
    "        speciesA, log = fusion(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "    \n",
    "    elif r <= 0.95:\n",
    "        speciesA, log = fusion(speciesA, mixing = 0.5)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "        \n",
    "    else:\n",
    "        speciesA, log = syntenyloss(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import random\n",
    "from random import randrange\n",
    "\n",
    "# Disable chained assignments\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "# Inputs\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description = __doc__,\n",
    "                                     formatter_class = argparse.RawDescriptionHelpFormatter)\n",
    "    parser.add_argument('-c', '--Nchr', type = int, \n",
    "                        required = False, default = 20,\n",
    "                        help = 'Number of chromosome in the ancestor')\n",
    "    parser.add_argument('-g', '--Ngene', type = int, \n",
    "                        required = False, default = 100,\n",
    "                        help = \"Number of genes on each chromosome\")\n",
    "    parser.add_argument('-n', '--Nevents', type = int, \n",
    "                        required = False, default = 10,\n",
    "                        help = \"Number of macro-syntetic rearrangement events\")\n",
    "    parser.add_argument('-p', \"--out_prefix\", type=str, \n",
    "                        required=False, default='Simulations/')\n",
    "    args = vars(parser.parse_args())\n",
    "    \n",
    "    Nchr = args['Nchr']\n",
    "    Ngene = args['Ngene']\n",
    "\n",
    "# Create output folder\n",
    "if '/' in args['out_prefix']:\n",
    "    folder = '/'.join(args['out_prefix'].split('/')[:-1])\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    \n",
    "# Make ancestor genome\n",
    "def makeancestor(Nchr, Ngene):\n",
    "    ancestor = pd.DataFrame(columns = ['Chr'])\n",
    "    for i in range(Nchr):\n",
    "        row = {'Chr' : (i + 1)}\n",
    "        for i in range(Ngene):\n",
    "                ancestor = pd.concat([ancestor, pd.DataFrame([row])], ignore_index = True)\n",
    "    ancestor['Genes'] = (ancestor.reset_index().index + 1)\n",
    "    # ancestor['Genes'] = 'g_' + ancestor['Genes'].astype(str)\n",
    "\n",
    "    return ancestor\n",
    "\n",
    "# Dummy BED files :: type 'anc' for ancestor, 'des' for descendant\n",
    "def dummyBED(genome, type, outfile):\n",
    "    if type == 'anc':\n",
    "        genome['Chr'] = 'AncChr' + genome['Chr'].astype(str)\n",
    "        genome['Genes'] = 'ancg_' + genome['Genes'].astype(str)\n",
    "        \n",
    "    if type == 'des':\n",
    "        genome['Chr'] = 'Chr' + genome['Chr'].astype(str)\n",
    "        genome['Genes'] = 'g_' + genome['Genes'].astype(str)\n",
    "    \n",
    "    genome['Start'] = np.arange(len(genome))\n",
    "    genome['End'] = np.arange(len(genome)) + 5\n",
    "    \n",
    "    genome = genome[['Chr', 'Start', 'End', 'Genes']]\n",
    "    \n",
    "    with open(outfile, 'w') as out:\n",
    "        out.write(genome.to_string(header = False, index = False))\n",
    "        \n",
    "    return genome\n",
    "\n",
    "# Dummy ortholog file\n",
    "def dummyOrthologs(genome, outfile):\n",
    "    \n",
    "    orthologs = pd.DataFrame()\n",
    "    \n",
    "    orthologs['Orthologs'] = np.arange(len(genome)) + 1\n",
    "    orthologs['speciesA'] = np.arange(len(genome)) + 1\n",
    "    orthologs['speciesB'] = np.arange(len(genome)) + 1\n",
    "    \n",
    "    orthologs['Orthologs'] = 'orthologs_' + orthologs['Orthologs'].astype(str)\n",
    "    orthologs['speciesA'] = 'ancg_' + orthologs['speciesA'].astype(str)\n",
    "    orthologs['speciesB'] = 'g_' + orthologs['speciesB'].astype(str)\n",
    "    \n",
    "    with open(outfile, 'w') as out:\n",
    "        out.write(orthologs.to_string(header = False, index = False))\n",
    "\n",
    "def mixing(genome, mixing):\n",
    "    genes = genome['Genes'].to_numpy()\n",
    "    n = len(genes)\n",
    "    for i in range(int(mixing * n)):\n",
    "        g1, g2 = randrange(n), randrange(n)\n",
    "        genes[g2], genes[g1] = genes[g1], genes[g2]\n",
    "\n",
    "        genome['Genes'] = genes\n",
    "        # genome['Chr'] = f'{fuse1}x{fuse2}'\n",
    "        \n",
    "def fusion(genome, mixing = 0):\n",
    "    '''\n",
    "    inputs: \n",
    "    ancestor : df with chromosome name | gene name\n",
    "    mixing : float between 0 and 1, where 1 implies extreme mixing and 0 implies no mixing\n",
    "    '''\n",
    "    \n",
    "    # Randomly select two chromosomes to fuse\n",
    "    fuse1 = random.choice(genome.Chr.unique())\n",
    "    fuse2 = random.choice(genome.Chr.unique())\n",
    "    \n",
    "    if fuse1 == fuse2: # Just so the same chromosome isn't selected twice\n",
    "        fuse2 = random.choice(range(1, len(genome.Chr.unique())))\n",
    "\n",
    "    fusion = ancestor.loc[ancestor['Chr'].isin([fuse1, fuse2])]\n",
    "    \n",
    "    # Apply mixing if required\n",
    "    if mixing > 0:\n",
    "        genes = fusion['Genes'].to_numpy()\n",
    "        n = len(genes)\n",
    "        for i in range(int(mixing * n)):\n",
    "            g1, g2 = randrange(n), randrange(n)\n",
    "            genes[g2], genes[g1] = genes[g1], genes[g2]\n",
    "\n",
    "        fusion['Genes'] = genes\n",
    "        fusion['Chr'] = f'{fuse1}x{fuse2}'\n",
    "        \n",
    "    else:\n",
    "         fusion['Chr'] = f'{fuse1}+{fuse2}'\n",
    "    \n",
    "    # Remove the unfused chromosomes\n",
    "    genome.drop(genome[genome['Chr'].isin([fuse1, fuse2])].index, inplace = True)\n",
    "    genome = pd.concat([genome, fusion])\n",
    "    \n",
    "    log = f'Fusion of AncChr{fuse1} and AncChr{fuse2} into Chr{fuse1}+{fuse2}'\n",
    "    \n",
    "    return genome, log\n",
    "\n",
    "def fission(genome):\n",
    "    # Randomly select a chromosome for fission\n",
    "    fiss = random.choice(genome.Chr.unique())\n",
    "    fission = genome.loc[genome['Chr'] == fiss]\n",
    "\n",
    "    pos = random.choice(range(1, Ngene))\n",
    "\n",
    "    # Add the new chromosomes back into the genome\n",
    "    chr1 = fission.iloc[: pos]\n",
    "    chr1['Chr'] = f'{fiss}_1'\n",
    "    chr2 = fission.iloc[pos :]\n",
    "    chr2['Chr'] = f'{fiss}_2'\n",
    "    \n",
    "    # Remove the fission chromosome from the genome\n",
    "    genome = pd.concat([genome, chr1, chr2])\n",
    "    genome = genome[genome.Chr != fiss]\n",
    "    \n",
    "    log = f'Fission of AncChr{fiss} into Chr{fiss}_1 and Chr{fiss}_2'\n",
    "    \n",
    "    return genome, log\n",
    "\n",
    "def translocation(genome):\n",
    "    # Randomly select two chromosomes for translocation\n",
    "    cA = random.choice(genome.Chr.unique())\n",
    "    cB = random.choice(genome.Chr.unique())\n",
    "    \n",
    "    chrA = genome.loc[genome['Chr'] == cA]\n",
    "    chrB = genome.loc[genome['Chr'] == cB]\n",
    "    \n",
    "    # Randomly select two break point positions\n",
    "    posA = random.choice(range(1, Ngene))\n",
    "    posB = random.choice(range(1, Ngene))\n",
    "    \n",
    "    # Join the fragments to form recombinant chromosomes\n",
    "    chr1 = pd.concat([chrA.iloc[: posA], chrB.iloc[posB :]])\n",
    "    chr1['Chr'] = f'{cA};{cB}'\n",
    "    chr2 = pd.concat([chrB.iloc[: posB], chrA.iloc[posA :]])\n",
    "    chr2['Chr'] = f'{cA};{cB}'\n",
    "    \n",
    "    # Remove the original chromosomes from the genome\n",
    "    genome = pd.concat([genome, chr1, chr2]).drop(genome[(genome['Chr'] == cA) & (genome['Chr'] == cB)].index)\n",
    "    \n",
    "    log = f'Translocation between AncChr{cA} and AncChr{cB}'\n",
    "    \n",
    "    return genome, log\n",
    "\n",
    "\n",
    "def synteny_loss(genome):\n",
    "    syn = random.choice(genome.Chr.unique())\n",
    "    synchr = genome.loc[genome['Chr'] == syn]\n",
    "    genome = genome[genome.Chr != syn]\n",
    "    \n",
    "    # Assign all elements to a random chromosome\n",
    "    synchr['Chr'] = random.choices(genome.Chr.unique(), k = len(synchr))\n",
    "    \n",
    "    # Add back into the genome\n",
    "    genome = genome.append(synchr)\n",
    "    \n",
    "    log = f'Synteny loss of AncChr{syn}'\n",
    "\n",
    "    return genome, log\n",
    "\n",
    "# Apply macro-rearrangements to the ancestor\n",
    "ancestor = makeancestor(Nchr, Ngene)\n",
    "speciesA = ancestor.copy()\n",
    "\n",
    "events = {}\n",
    "for event in range(args['Nevents']):\n",
    "    r = np.random.uniform()\n",
    "    \n",
    "    if r <= 0.40:\n",
    "        if len(ancestor) < 2: continue\n",
    "        speciesA, log = fission(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "    \n",
    "    elif r <= 0.70:\n",
    "        speciesA, log = fusion(speciesA)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "    \n",
    "    else:\n",
    "        speciesA, log = fusion(speciesA, mixing = 0.5)\n",
    "        events['EVENT_' + str(event + 1)] = log\n",
    "        print(log)\n",
    "        continue\n",
    "    \n",
    "# Create BED files and orthology file\n",
    "outfile = args['out_prefix'] + 'SpeciesA.genelist.bed'\n",
    "dummyBED(speciesA, 'des', outfile)\n",
    "outfile = args['out_prefix'] + 'Ancestor.genelist.bed'\n",
    "dummyBED(ancestor, 'anc', outfile)\n",
    "outfile = args['out_prefix'] + 'Ancestor+SpeciesA.txt'\n",
    "dummyOrthologs(ancestor, outfile)\n",
    "\n",
    "# Create list of rearrangements\n",
    "outfile = args['out_prefix'] + 'rearrangements.txt'\n",
    "with open(outfile, 'w') as out:\n",
    "    for event in events:\n",
    "        out.write(f'{event}: {events[event]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fissions = data.pivot(index = 'A', columns='B', values = 'Orthologs')\n",
    "fissions = fissions.loc[(fissions.where(fissions.isnull(), 1).sum(axis=1) > 1) | (fissions.sum(axis=0) > 1)]\n",
    "fissions = fissions.stack(dropna = True).reset_index().groupby('A')['B'].apply(list).reset_index(name = 'B')\n",
    "fissions['B'] = [', '.join(map(str, l)) for l in fissions['B']]\n",
    "\n",
    "translocations = fissions.groupby('B').filter(lambda g: len(g) > 1)\n",
    "\n",
    "fissions = fissions[~ fissions.isin(translocations)]\n",
    "fissions.dropna(inplace =True)\n",
    "\n",
    "fusions = data.pivot(index = 'B', columns = 'A', values = 'Orthologs')\n",
    "fusions = fusions.loc[(fusions.where(fusions.isnull(), 1).sum(axis=1) > 1) | (fusions.sum(axis=0) > 1)]\n",
    "fusions = fusions.stack(dropna = True).reset_index()\n",
    "\n",
    "fusions = fusions[~ fusions.isin(translocations)]\n",
    "translocations = translocations.groupby('B')['A'].apply(list).reset_index()\n",
    "translocations['A'] = [', '.join(map(str, l)) for l in translocations['A']]\n",
    "translocations = translocations.groupby('A')['B'].apply(list).reset_index()\n",
    "translocations['B'] = [', '.join(map(str, l)) for l in translocations['B']]\n",
    "\n",
    "translocations = translocations.groupby('B')['A'].apply(list).reset_index()\n",
    "translocations['A'] = [', '.join(map(str, l)) for l in translocations['A']]\n",
    "translocations = translocations.groupby('A')['B'].apply(list).reset_index()\n",
    "translocations['B'] = [', '.join(map(str, l)) for l in translocations['B']]\n",
    "\n",
    "fusions = fusions.groupby('B')['A'].apply(list).reset_index(name = 'A')\n",
    "fusions['A'] = [', '.join(map(str, l)) for l in fusions['A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.strip() for xs in fissions.B.values.tolist() for x in xs.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".groupby('A')['B'].apply(list).reset_index(name = 'B')\n",
    "\n",
    "fissions['B'] = [', '.join(map(str, l)) for l in fissions['B']]\n",
    "\n",
    "translocations = fissions.groupby('B').filter(lambda g: len(g) > 1)\n",
    "fissions.dropna(inplace = True)\n",
    "\n",
    "fusions = data.pivot(index = 'B', columns = 'A', values = 'Orthologs')\n",
    "fusions = fusions.loc[(fusions.where(fusions.isnull(), 1).sum(axis = 1) > 1) | (fusions.sum(axis = 0) > 1)]\n",
    "fusions = fusions.stack(dropna = True).reset_index()\n",
    "\n",
    "translocations = translocations.groupby('B')['A'].apply(list).reset_index()\n",
    "translocations['A'] = [', '.join(map(str, l)) for l in translocations['A']]\n",
    "translocations = translocations.groupby('A')['B'].apply(list).reset_index()\n",
    "translocations['B'] = [', '.join(map(str, l)) for l in translocations['B']]\n",
    "\n",
    "translocations = translocations.groupby('B')['A'].apply(list).reset_index()\n",
    "translocations['A'] = [', '.join(map(str, l)) for l in translocations['A']]\n",
    "translocations = translocations.groupby('A')['B'].apply(list).reset_index()\n",
    "translocations['B'] = [', '.join(map(str, l)) for l in translocations['B']]\n",
    "\n",
    "fusions = fusions.groupby('B')['A'].apply(list).reset_index(name = 'A')\n",
    "fusions['A'] = [', '.join(map(str, l)) for l in fusions['A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrangements(data, outfile = 'F'):\n",
    "    # Converts table into dotplot\n",
    "    fissions = data.pivot(index = 'A', columns='B', values = 'Orthologs')\n",
    "    \n",
    "    # Picks out all rows and columns with more than one dot\n",
    "    fissions = fissions.loc[(fissions.where(fissions.isnull(), 1).sum(axis=1) > 1) | (fissions.sum(axis=0) > 1)]\n",
    "    fissions = fissions.stack(dropna = True).reset_index().groupby('A')['B'].apply(list).reset_index(name = 'B')\n",
    "    fissions['B'] = [', '.join(map(str, l)) for l in fissions['B']] # Convert list to str\n",
    "\n",
    "    # Identify all translocations\n",
    "    translocations = fissions.groupby('B').filter(lambda g: len(g) > 1)\n",
    "    # Remove all translocations from list of fissions\n",
    "    fissions = fissions[~ fissions.isin(translocations)]\n",
    "    fissions.dropna(inplace = True)\n",
    "\n",
    "    # Converts table into dotplot\n",
    "    fusions = data.pivot(index = 'B', columns = 'A', values = 'Orthologs')\n",
    "    fusions = fusions.loc[(fusions.where(fusions.isnull(), 1).sum(axis=1) > 1) | (fusions.sum(axis=0) > 1)]\n",
    "    fusions = fusions.stack(dropna = True).reset_index()\n",
    "    \n",
    "    # Picks out all rows and columns with more than one dot\n",
    "    translocations = fusions.groupby('A').filter(lambda g: len(g) > 1)\n",
    "    \n",
    "    # Remove all translocations from list of fissions\n",
    "    fusions = fusions[~ fusions.isin(translocations)]\n",
    "\n",
    "    # Identify and isolate the translocations\n",
    "    translocations = translocations.groupby('B')['A'].apply(list).reset_index()\n",
    "    translocations['A'] = [', '.join(map(str, l)) for l in translocations['A']]\n",
    "    translocations = translocations.groupby('A')['B'].apply(list).reset_index()\n",
    "    translocations['B'] = [', '.join(map(str, l)) for l in translocations['B']]\n",
    "\n",
    "    fusions = fusions.groupby('B')['A'].apply(list).reset_index(name = 'A')\n",
    "    fusions['A'] = [', '.join(map(str, l)) for l in fusions['A']]\n",
    "\n",
    "    events = []\n",
    "    for index, row in fissions.iterrows():\n",
    "        str = (''.join(('Fission of ancestral chromosome ', str(row['A']), ' into ', str(row['B']))))\n",
    "        print(str)\n",
    "        events.append(str)\n",
    "\n",
    "    for index, row in fusions.iterrows():\n",
    "        str = (''.join(('Fusion of ancestral chromosome ', str(row['A']), ' into ', str(row['B']))))\n",
    "        print(str)\n",
    "        events.append(str)\n",
    "        \n",
    "    for index, row in translocations.iterrows():\n",
    "        str = (''.join(('Translocation between ancestral chromosome ', print(row['A']), ' into ', str(row['B']))))\n",
    "        print(str)\n",
    "        events.append(str)\n",
    "    \n",
    "    if outfile != 'F':\n",
    "        with open(outfile, 'w') as out:\n",
    "            out.write('\\n'.join(events))\n",
    "\n",
    "    fusions['Events'] = 'FUS'\n",
    "    fissions['Events'] = 'FIS'\n",
    "    translocations['Events'] = 'TRA'\n",
    "\n",
    "    log = pd.concat([fusions, fissions, translocations])\n",
    "    log = events[['Events', 'A', 'B']]\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts the rearrangements\n",
    "for i in range(100+1):\n",
    "    input = 'Simulations/Ancestor_' + str(i) + '.bed'\n",
    "    ancestor = Orthoscripts.readBED(input, 's')\n",
    "    input = 'Simulations/SpeciesA_' + str(i) + '.bed'\n",
    "    speciesA = Orthoscripts.readBED(input, 's')\n",
    "    input = 'Simulations/Ancestor+SpeciesA_' + str(i) + '.txt'\n",
    "    orthos = np.loadtxt(input, dtype = \"str\")\n",
    "\n",
    "    data = Orthoscripts.orthologies(ancestor, speciesA, orthos)\n",
    "    \n",
    "    outfile = 'Simulations/Rearrangements_' + str(i) + '.txt'\n",
    "    Orthoscripts.rearrangements(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(Nchr = 20, Ngene = 100, Nevents = 10, Nruns = 1):\n",
    "    def makeancestor(Nchr, Ngene):\n",
    "        ancestor = pd.DataFrame(columns = ['Chromosome'])\n",
    "        for i in range(Nchr):\n",
    "            row = {'Chromosome' : (i + 1)}\n",
    "            for i in range(Ngene):\n",
    "                    ancestor = pd.concat([ancestor, pd.DataFrame([row])], ignore_index = True)\n",
    "        ancestor['Name'] = (ancestor.reset_index().index + 1)\n",
    "\n",
    "        return ancestor\n",
    "\n",
    "    # Dummy BED files :: type 'anc' for ancestor, 'des' for descendant\n",
    "    def dummyBED(genome, type):\n",
    "        if type == 'anc':\n",
    "            genome['Chromosome'] = 'AncChr' + genome['Chromosome'].astype(str)\n",
    "            genome['Name'] = 'ancg_' + genome['Name'].astype(str)\n",
    "            \n",
    "        if type == 'des':\n",
    "            genome['Chromosome'] = 'Chr' + genome['Chromosome'].astype(str)\n",
    "            genome['Name'] = 'g_' + genome['Name'].astype(str)\n",
    "        \n",
    "        genome['Start'] = np.arange(len(genome))\n",
    "        genome['End'] = np.arange(len(genome)) + 5\n",
    "        \n",
    "        genome = genome[['Chromosome', 'Start', 'End', 'Name']]\n",
    "            \n",
    "        return genome\n",
    "\n",
    "    # Dummy ortholog file\n",
    "    def dummyOrthologs(genome):\n",
    "        orthologs = pd.DataFrame()\n",
    "        \n",
    "        orthologs['Orthologs'] = np.arange(len(genome)) + 1\n",
    "        orthologs['speciesA'] = np.arange(len(genome)) + 1\n",
    "        orthologs['speciesB'] = np.arange(len(genome)) + 1\n",
    "        \n",
    "        orthologs['Orthologs'] = 'orthologs_' + orthologs['Orthologs'].astype(str)\n",
    "        orthologs['speciesA'] = 'ancg_' + orthologs['speciesA'].astype(str)\n",
    "        orthologs['speciesB'] = 'g_' + orthologs['speciesB'].astype(str)\n",
    "        \n",
    "        orthologs = orthologs.to_numpy()\n",
    "        \n",
    "        return orthologs\n",
    "\n",
    "    def mixing(genome, mixing):\n",
    "        genes = genome['Name'].to_numpy()\n",
    "        n = len(genes)\n",
    "        for i in range(int(mixing * n)):\n",
    "            g1, g2 = randrange(n), randrange(n)\n",
    "            genes[g2], genes[g1] = genes[g1], genes[g2]\n",
    "\n",
    "            genome['Name'] = genes\n",
    "            # genome['Chromosome'] = f'{fuse1}x{fuse2}'\n",
    "            \n",
    "    def fusion(genome, chr, mixing = 0):\n",
    "        '''\n",
    "        inputs: \n",
    "        ancestor : df with chromosome name | gene name\n",
    "        mixing : float between 0 and 1, where 1 implies extreme mixing and 0 implies no mixing\n",
    "        '''\n",
    "        \n",
    "        # Randomly select two chromosomes to fuse\n",
    "        A = random.choice(chr)\n",
    "        B = random.choice(chr)\n",
    "        \n",
    "        chr = [x for x in chr if x not in (A, B)]\n",
    "        \n",
    "        if A == B: # Just so the same chromosome isn't selected twice\n",
    "            B = random.choice(chr)\n",
    "\n",
    "        fusion = ancestor.loc[ancestor['Chromosome'].isin([A, B])]\n",
    "        \n",
    "        # Apply mixing if required\n",
    "        if mixing > 0:\n",
    "            genes = fusion['Name'].to_numpy()\n",
    "            n = len(genes)\n",
    "            for i in range(int(mixing * n)):\n",
    "                g1, g2 = randrange(n), randrange(n)\n",
    "                genes[g2], genes[g1] = genes[g1], genes[g2]\n",
    "\n",
    "            fusion['Name'] = genes\n",
    "            fusion['Chromosome'] = f'{A}x{B}'\n",
    "            log = f'Fusion of ancestral chromosome AncChr{A}, AncChr{B} into Chr{A}x{B}'\n",
    "            \n",
    "        else:\n",
    "            fusion['Chromosome'] = f'{A}+{B}'\n",
    "            log = f'Fusion of ancestral chromosome AncChr{A}, AncChr{B} into Chr{A}+{B}'\n",
    "        \n",
    "        # Remove the unfused chromosomes\n",
    "        genome.drop(genome[genome['Chromosome'].isin([A, B])].index, inplace = True)\n",
    "        genome = pd.concat([genome, fusion])\n",
    "        \n",
    "        return genome, log, chr\n",
    "\n",
    "    def fission(genome, chr):\n",
    "        # Randomly select a chromosome for fission\n",
    "        A = random.choice(chr)\n",
    "        fission = genome.loc[genome['Chromosome'] == A]\n",
    "        chr.remove(A)\n",
    "        \n",
    "        pos = random.choice(range(1, Ngene))\n",
    "\n",
    "        # Add the new chromosomes back into the genome\n",
    "        chr1 = fission.iloc[: pos]\n",
    "        chr1['Chromosome'] = f'{A}_1'\n",
    "        \n",
    "        chr2 = fission.iloc[pos :]\n",
    "        chr2['Chromosome'] = f'{A}_2'\n",
    "        \n",
    "        # Remove the fission chromosome from the genome\n",
    "        genome = pd.concat([genome, chr1, chr2])\n",
    "        genome = genome[genome.Chromosome != A]\n",
    "        \n",
    "        log = f'Fission of ancestral chromosome AncChr{A} into Chr{A}_1, Chr{A}_2'\n",
    "        \n",
    "        return genome, log, chr\n",
    "\n",
    "    def translocation(genome, chr):\n",
    "        # Randomly select two chromosomes for translocation\n",
    "        A = random.choice(chr)\n",
    "        B = random.choice(chr)\n",
    "        \n",
    "        if A == B: # Just so the same chromosome isn't selected twice\n",
    "            B = random.choice(chr)\n",
    "        \n",
    "        chr = [x for x in chr if x not in (A, B)]\n",
    "        \n",
    "        chrA = genome.loc[genome['Chromosome'] == A]\n",
    "        chrB = genome.loc[genome['Chromosome'] == B]\n",
    "        \n",
    "        # Randomly select two break point positions\n",
    "        posA = random.choice(range(1, Ngene))\n",
    "        posB = random.choice(range(1, Ngene))\n",
    "        \n",
    "        # Join the fragments to form recombinant chromosomes\n",
    "        chr1 = pd.concat([chrA.iloc[: posA], chrB.iloc[posB :]])\n",
    "        chr1['Chromosome'] = f'{A};{B}'\n",
    "        chr2 = pd.concat([chrB.iloc[: posB], chrA.iloc[posA :]])\n",
    "        chr2['Chromosome'] = f'{B};{A}'\n",
    "        \n",
    "        # Remove the original chromosomes from the genome\n",
    "        genome = pd.concat([genome, chr1, chr2]).drop(genome[(genome['Chromosome'] == A) & (genome['Chromosome'] == B)].index)\n",
    "        \n",
    "        log = f'Translocation of ancestral chromosomes AncChr{A}, AncChr{B} into Chr{A};{B}, Chr{B};{A}'\n",
    "        \n",
    "        return genome, log, chr\n",
    "\n",
    "    def syntenyloss(genome, chr):\n",
    "        A = random.choice(chr)\n",
    "        syn = genome.loc[genome['Chromosome'] == A]\n",
    "        genome = genome[genome.Chromosome != syn]\n",
    "        \n",
    "        chr.remove(A)\n",
    "        \n",
    "        # Assign all elements to a random chromosome\n",
    "        syn['Chromosome'] = random.choices(genome.Chromosome.unique(), k = len(syn))\n",
    "        \n",
    "        # Add back into the genome\n",
    "        genome = pd.concat([genome, syn])\n",
    "        \n",
    "        log = f'Synteny loss of AncChr{A}'\n",
    "\n",
    "        return genome, log, chr\n",
    "\n",
    "    # Apply macro-rearrangements to the ancestor\n",
    "    ancestor = makeancestor(Nchr, Ngene)\n",
    "    chr = ancestor.Chromosome.unique().tolist()\n",
    "    speciesA = ancestor.copy()\n",
    "\n",
    "    events = []\n",
    "    for event in range(Nevents):\n",
    "        r = np.random.uniform()\n",
    "        \n",
    "        if r <= 0.30:\n",
    "            if len(ancestor) < 2: continue\n",
    "            speciesA, log, chr = fission(speciesA, chr)\n",
    "            events.append(log)\n",
    "        \n",
    "        elif r <= 0.45:\n",
    "            speciesA, log, chr = translocation(speciesA, chr)\n",
    "            events.append(log)\n",
    "        \n",
    "        elif r <= 0.70:\n",
    "            speciesA, log, chr = fusion(speciesA, chr)\n",
    "            events.append(log)\n",
    "        \n",
    "        elif r <= 0.99:\n",
    "            speciesA, log, chr = fusion(speciesA, chr, mixing = 0.5)\n",
    "            events.append(log)\n",
    "            \n",
    "        else:\n",
    "            # speciesA, log, chr = syntenyloss(speciesA, chr)\n",
    "            # events.append(log)\n",
    "            # print(log)\n",
    "            continue\n",
    "        \n",
    "    ancestor = dummyBED(ancestor, 'anc')\n",
    "    speciesA = dummyBED(speciesA, 'des')\n",
    "    orthologs = dummyOrthologs(ancestor)\n",
    "    \n",
    "    return ancestor, speciesA, orthologs, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    r = np.random.uniform()\n",
    "    if r <= 0.30:\n",
    "        # Join the fragments to form recombinant chromosomes\n",
    "        chr1 = pd.concat([chrA.iloc[: posA], chrB.iloc[posB :]])\n",
    "        chr1['Chr'] = f'{A};{B}'\n",
    "        chr2 = pd.concat([chrB.iloc[: posB], chrA.iloc[posA :]])\n",
    "        chr2['Chr'] = f'{B};{A}'\n",
    "        \n",
    "        log = f'TR AncChr{A}, AncChr{B} Chr{A};{B}, Chr{B};{A}'\n",
    "    \n",
    "    else:\n",
    "        chr1 = pd.concat([chrA.iloc[: posA]])\n",
    "        chr1['Chr'] = f'{A};'\n",
    "        chr2 = pd.concat([chrB, chrA.iloc[posA :]])\n",
    "        chr2['Chr'] = f'{B};{A}'\n",
    "    \n",
    "        log = f'TR AncChr{A}, AncChr{B} Chr{B};{A}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
